# @package _group_

agent_type: "DQNfD"

hyper_params:
  gamma: 0.99
  tau: 0.005
  buffer_size: 100000             # openai baselines: 10000
  batch_size: 64                  # openai baselines: 32
  update_starts_from: 10000       # openai baselines: 10000
  multiple_update: 1              # multiple learning updates
  train_freq: 8                   # in openai baselines, train_freq = 4
  gradient_clip: 0.5              # dueling: 10.0
  n_step: 3
  w_n_step: 1.0
  w_q_reg: 0.0000001
  per_alpha: 0.6                  # openai baselines: 0.6
  per_beta: 0.4
  per_eps: 0.001
  # fD
  per_eps_demo: 1.0
  lambda1: 1.0                    # N-step return weight
  lambda2: 1.0                    # Supervised loss weight
  # lambda3 = weight_decay (l2 regularization weight)
  margin: 0.8
  pretrain_step: 100
  max_epsilon: 1.0
  min_epsilon: 0.0                # openai baselines: 0.01
  epsilon_decay: 0.00002          # openai baselines: 1e-7 / 1e-1
  demo_path: "data/lunarlander_discrete_demo.pkl"

learner_cfg:
  backbone:
  head:
    type: "MLP"
    configs:
      hidden_sizes: [128, 64]
      v_min: -300
      v_max: 300
      atom_size: 1530
      output_activation: "identity"
      use_noisy_net: False
  optim_cfg:
    lr_dqn: 0.0001
    weight_decay: 0.00001
    adam_eps: 0.00000001